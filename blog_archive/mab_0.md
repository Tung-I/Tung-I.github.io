---
title: "Introduction of Multi-Armed Bandits"
layout: single
permalink: /blog_archive/mab_0
classes: wide
author_profile: true
---
<!-- ![](/assets/images/trees.jpg)
*image_caption* -->
<!-- 
{% include figure image_path="/assets/images/trees.jpg" alt="this is a placeholder image" caption="This is a figure caption." %} -->

{% include figure image_path="/assets/images/mab_illustration.jpg" alt="this is a placeholder image" caption="image from \"https://vwo.com/blog/multi-armed-bandit-algorithm/\" " %} 


**MAB (multi-armed bandits)** is a simple yet powerful framework for algorithms making decisions over time under uncertainty. This name was inspired by the slot machine in casinos, aka one-armed bandits, as the reward can only be observed after pulling the lever. Similarly, the spirit of MAB is to maximize the cumulative reward without full knowledge of the reward distribution of each arm. 

to be continued ...

